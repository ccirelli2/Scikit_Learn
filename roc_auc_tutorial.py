''' Description:  Tutorial on ROC & AUC Curves
    URL: https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc
        https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5
    Video: https://www.dataschool.io/roc-curves-and-auc-explained/

    ROC Curve: Used for binary classifiers

    ROC Curve (receiver operating characteristic curve) is a graph showing the performance of
    a classification model at all classification thresholds.  The curve plots
        True Positive (recall) = TP / (TP + FN)
        False Positive = FP / (FP + TN)
    ROC is the probability and AUC represents the degree or measure of separability. 
    The higher the AUC the better the model at predicting the target. 

    The ROC curve is plotted with TPR against FPR where TPR is on the y-axis. 
        
    Video: great explanation of how the ROC curve is generated, purpose, utilizty and
    what thresholds mean (think logistic regression and setting prediction threshold)

'''







